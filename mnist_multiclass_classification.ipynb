{"cells":[{"cell_type":"markdown","metadata":{"id":"jZskgnPeB81k"},"source":["# Multiclass Classification"]},{"cell_type":"markdown","metadata":{"id":"fHmUZEYWDYZn"},"source":["Classification is a task where the goal is to predict a target variable based on a set of input features. \n","\n","The input features can be continuous, discrete or categorical.\n","\n","Some types of classification:\n","* **Binary classification**: The target variable has only two possible classes or outcomes.\n","* **Multi-class classification**: The target variable has three or more possible classes or outcomes.\n","* **Multi-label classification**: The target variable has two or more labels and each instance can belong to one or more of these labels.\n","* **Imbalanced classification**: The target variable has a disproportionate number of instances in different classes.\n","* **Hierarchical classification**: The target variable has a hierarchical structure, where the classes are organized in a tree-like structure."]},{"cell_type":"markdown","metadata":{"id":"9G-FnnJpsl6u"},"source":["## 1. Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1959,"status":"ok","timestamp":1682970004816,"user":{"displayName":"guilherme guimarães","userId":"02034701674220013717"},"user_tz":180},"id":"sD2sqz8OrtOD"},"outputs":[],"source":["import seaborn as sns\n","import pandas as pd\n","from sklearn.datasets import fetch_openml\n","from sklearn.svm import SVC\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n","from sklearn.manifold import TSNE"]},{"cell_type":"markdown","metadata":{"id":"P2VQFeqewMI2"},"source":["**seaborn**:  is a Python data visualization library based on Matplotlib. \n","\n","**fetch_openml**: to fetch a dataset by your name or id.\n","\n","**SVC**: Support Vector Classification, it's a machine learning algorithm that which can be used for classification and regression and tries to find the optimal hyperplane that best separates two classes in a dataset.\n","\n","SVC (Support Vector Classification) is a popular supervised machine learning algorithm used for classification tasks. It is a type of Support Vector Machine (SVM) algorithm that can be used for both linear and non-linear classification problems. The goal of SVC is to find a hyperplane (decision boundary) that maximizes the margin (distance) between the different classes in the data. The data is classified based on which side of the hyperplane it falls on. SVC works well on both small and large datasets and is effective in handling high-dimensional data.\n","\n","In machine learning, a *hyperplane* is a decision boundary that separates the input feature space into two classes. It is a mathematical construct that is used in various supervised learning algorithms, including classification and regression. The goal of the algorithm is to find the hyperplane that maximally separates the data points based on their class labels.\n","\n","**cross_val_predict**: \"Generate cross-validated estimates for each input data point.\n","<font size=\"2\">(https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)</font>\n","\n","**confusion_matrix**: \"Compute confusion matrix to evaluate the accuracy of a classification.\"\n","<font size=\"2\">(https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)</font>\n","\n","**precision_score**: ratio that correctly identifies true positives over all considered positives (true and false positives).\n","\n","**recall_score**: ratio that correctly identifies true positives over identified and unidentified one's (true positives and false negatives).\n","\n","**f1_score**: combines the precision and the recall scores of a model, calculating the harmonic mean of precision and recall.\n","\n","**manifold and TSNE**: \n"]},{"cell_type":"markdown","metadata":{"id":"o_w1LVzMsmzT"},"source":["## 2. Load Dataset"]},{"cell_type":"markdown","metadata":{"id":"lMbwgYKbTnHP"},"source":["The MNIST dataset is a popular dataset of handwritten digits commonly used for training and testing machine learning models in the field of computer vision. It consists of a training set of 60,000 images and a test set of 10,000 images, each of which is a grayscale image of size 28x28 pixels. The images are labeled with the corresponding digit they represent, ranging from 0 to 9. The dataset is widely used as a benchmark for image classification tasks and has played a key role in advancing the field of computer vision.\n","\n","IMPORTANT: The MNIST dataset is the same in both Keras and Scikit-learn, but they are packaged and loaded in different ways.\n","\n","* **Keras**: the MNIST dataset is loaded as a set of four NumPy arrays: train images, train labels, test images, and test labels. The images are 28x28 grayscale images, and the labels are integer values representing the digit in the image.\n","* **Scikit-learn**: the MNIST dataset is loaded as a single 2D array of shape (n_samples, n_features), where n_samples is the number of images and n_features is the number of pixels in each image. The pixel values are flattened into a single row and scaled to the range [0, 1]. The labels are provided as a separate 1D array of length n_samples.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68345,"status":"ok","timestamp":1682970073158,"user":{"displayName":"guilherme guimarães","userId":"02034701674220013717"},"user_tz":180},"id":"eKdwfVAvsNUo","outputId":"33dbfcf7-e809-4320-de03-bb44dc0a08a9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}],"source":["# load dataset\n","mnist = fetch_openml('mnist_784', version=1)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1682970073160,"user":{"displayName":"guilherme guimarães","userId":"02034701674220013717"},"user_tz":180},"id":"n1w92U7oOSx2","outputId":"a25d810f-0443-4787-df78-271b47c9cff9"},"outputs":[{"output_type":"stream","name":"stdout","text":["MNIST datatype:  <class 'sklearn.utils._bunch.Bunch'>\n","MNIST columns:  dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])\n","X shape:  (70000, 784)\n","y shape:  (70000,)\n"]}],"source":["# check and split data\n","print('MNIST datatype: ', type(mnist))\n","\n","print('MNIST columns: ', mnist.keys())\n","\n","# splitting data and labels\n","X, y = mnist['data'], mnist['target']\n","\n","print('X shape: ', X.shape)\n","print('y shape: ', y.shape)"]},{"cell_type":"markdown","metadata":{"id":"LRtWgYR-snhc"},"source":["## 3. From splitting in **Train and Test** to the **Model**"]},{"cell_type":"markdown","metadata":{"id":"Vu30Eh4ufaZb"},"source":["\n","**SVC**: supports only a linear kernel, using a one-vs-one strategy (each class versus every other class.).\n","\n","**fit**: used to generate a learning model by training the parameters.\n","\n","**train and test mnist**: this database is pre-divided between the first 60.000 occurrences for training data and the last 10.000 occurrences for test data.\n","\n","**decision_function_shape='ovo'**: ovo stands for \"one-vs-one\" and means that the algorithm constructs one binary classifier for each pair of classes. Each classifier then predicts which of the two classes the input belongs to. "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"elapsed":288172,"status":"ok","timestamp":1682970361316,"user":{"displayName":"guilherme guimarães","userId":"02034701674220013717"},"user_tz":180},"id":"VHdRsATIsNf5","outputId":"e3aa052a-182f-4a21-a031-f0d135bcb9f1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC(decision_function_shape='ovo')"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(decision_function_shape=&#x27;ovo&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(decision_function_shape=&#x27;ovo&#x27;)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":4}],"source":["# splitting data into train and test\n","X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n","# splitting the first 60.000 that are designed for training and the last 10.000 for test\n","\n","svc_classification = SVC(decision_function_shape='ovo')\n","# decision_function_shape='ovo' \n","\n","# TRAINING the SVM classifier\n","svc_classification.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"Q4UYqP2Sskvl"},"source":["## 4. Predictions: in training and in testing"]},{"cell_type":"markdown","metadata":{"id":"nLsA62G-aV8g"},"source":["**prediction**: refers to using a trained model to make a prediction on new or unseen data. This involves passing the new data through the trained model to get a predicted outcome or label.\n","\n","**tain and test**: Data is split into training and testing sets in order to evaluate the performance of a machine learning model. The training set is used to train or fit the model on a subset of the data, while the testing set is used to evaluate the model's performance on new or unseen data. This helps to assess whether the model is overfitting or underfitting the data, and to estimate how well it will perform on new data. The idea is to evaluate the model on data that it has not seen during training to estimate how well it will generalize to new data."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1682970361318,"user":{"displayName":"guilherme guimarães","userId":"02034701674220013717"},"user_tz":180},"id":"r_Hak-xGsNiw","outputId":"db51f063-9ae8-4ce1-968b-a79b38050a35"},"outputs":[{"output_type":"stream","name":"stdout","text":["TRAINING predictions: \n","\n","Predicted: 5, Actual: 5\n","Predicted: 0, Actual: 0\n","Predicted: 4, Actual: 4\n","Predicted: 1, Actual: 1\n","Predicted: 9, Actual: 9\n","Predicted: 2, Actual: 2\n","Predicted: 1, Actual: 1\n","Predicted: 3, Actual: 3\n","Predicted: 1, Actual: 1\n","Predicted: 4, Actual: 4\n"]}],"source":["# Predictions in training\n","training_prediction = svc_classification.predict(X_train[:10])\n","\n","# showing prediction and the current value\n","print('TRAINING predictions: \\n')\n","for pred, actual in zip(training_prediction, y_train):\n","    print(f\"Predicted: {pred}, Actual: {actual}\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":742,"status":"ok","timestamp":1682970362042,"user":{"displayName":"guilherme guimarães","userId":"02034701674220013717"},"user_tz":180},"id":"t3gR8goitc5u","outputId":"36479cba-5cb2-44ae-9775-5f7051205ebe"},"outputs":[{"output_type":"stream","name":"stdout","text":["TESTING predictions: \n","\n","Predicted: 7, Actual: 7\n","Predicted: 2, Actual: 2\n","Predicted: 1, Actual: 1\n","Predicted: 0, Actual: 0\n","Predicted: 4, Actual: 4\n","Predicted: 1, Actual: 1\n","Predicted: 4, Actual: 4\n","Predicted: 9, Actual: 9\n","Predicted: 6, Actual: 5\n","Predicted: 9, Actual: 9\n"]}],"source":["# Predictions in testing\n","testing_prediction = svc_classification.predict(X_test[:10])\n","\n","# showing prediction and the current value\n","print('TESTING predictions: \\n')\n","for pred, actual in zip(testing_prediction, y_test):\n","    print(f\"Predicted: {pred}, Actual: {actual}\")"]},{"cell_type":"markdown","metadata":{"id":"DoRdSFVJtZ51"},"source":["## 5. Evaluation"]},{"cell_type":"markdown","metadata":{"id":"a6hfJuEqaQyx"},"source":["Evaluation refers to the process of assessing the performance of a model on a particular task or dataset. \n","The goal of evaluation is to determine how well a model is able to generalize to new, unseen data.\n","Evaluation can be done in different ways depending on the task and the problem being solved.\n","It is important to evaluate a model to ensure that it is not overfitting to the training data, and that it is able to generalize to new data. \n","This helps to ensure that the model is useful for real-world applications.\n","\n","There are several evaluation metrics that can be used for machine learning classification problems, for example:\n","* **Accuracy**: the proportion of correct predictions out of the total number of predictions.\n","* **Precision**: the proportion of true positives (correctly identified positives) out of all predicted positives.\n","* **Recall**: the proportion of true positives out of all actual positives (true positives + false negatives).\n","* **F1 score**: the harmonic mean of precision and recall, which balances both metrics.\n","* **Confusion matrix**: a table that shows the number of true positives, false positives, true negatives, and false negatives.\n","* **ROC curve**: a graph that shows the trade-off between true positive rate and false positive rate for different classification thresholds.\n","* **AUC score**: the area under the ROC curve, which measures the overall performance of a classifier."]},{"cell_type":"markdown","metadata":{"id":"zWd_ILN69Yxu"},"source":["**Cross Validation**: \n","\n","cross_val_predict is a function provided by scikit-learn that performs cross-validation by splitting the data into **k** folds and returns predicted class labels for each observation in the input data using the estimator object passed as an argument.\n","\n","can be used for both classification and regression problems. For classification problems, it returns the predicted class labels for each observation in the input data.\n","\n","The function is similar to cross_val_score but instead of returning the evaluation metric score, it returns the predicted labels for each fold. This function can be used to generate cross-validated estimates for the data, which is useful for assessing the performance of a model and avoiding overfitting.\n","\n","\"Generate cross-validated estimates for each input data point.\n","The data is split according to the cv parameter. Each sample belongs to exactly one test set, and its prediction is computed with an estimator fitted on the corresponding training set.\"\n","\n","**cv=**: \"Determines the cross-validation splitting strategy\".\n","\n","<font size=\"2\">reference: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OWQ5r2eZsNlV"},"outputs":[],"source":["y_train_predict = cross_val_predict(svc_classification, X_train, y_train, cv=3) # ??????????????????????????? manter?"]},{"cell_type":"markdown","metadata":{"id":"uL0C9wrVEpjG"},"source":["**confusion_matrix**: \n","\n","is a table that is used to evaluate the performance of a classification model. It is a 2-dimensional table that shows the number of correct and incorrect predictions made by the model. The table is organized into rows and columns, where each row represents the instances in a predicted class while each column represents the instances in an actual class.\n","\n","The confusion matrix provides various measures of the model's performance, such as accuracy, precision, recall, and F1 score. It is also useful for identifying the types of errors made by the model, such as false positives and false negatives, which can help in understanding and improving the model's performance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DdRwOSofEpPc"},"outputs":[],"source":["confusion_matrix_array = confusion_matrix(y_train, y_train_predict)\n","\n","print(\"confusion_matrix_array: \\n\")\n","print(confusion_matrix_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"swW3H3XV_s0u"},"outputs":[],"source":["precision = precision_score(y_train, y_train_predict, average=\"micro\")\n","recall = recall_score(y_train, y_train_predict, average=\"micro\")\n","f1score = f1_score(y_train, y_train_predict, average=\"micro\")\n","\n","'''\n","average= is used to specify the type of averaging to be applied to the individual scores, \n","in order to obtain an overall score that summarizes the performance of the classifier.\n","The \"micro\" average computes a single score by considering all the true positives, false positives, and false negatives of each class, \n","and then aggregating those counts.\n","'''\n","\n","print(\"Precision: \", precision)\n","print(\"Recall: \", recall)\n","print(\"f1_score: \", f1score)"]},{"cell_type":"markdown","metadata":{"id":"U-n0Sr5lI6sm"},"source":["## 6. Plotting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PbzdUyCDJc3H"},"outputs":[],"source":["x_train, y_train = mnist['data'], mnist['target']\n","x_train = x_train[:3000]\n","y_train = y_train[:3000]\n","\n","print(x_train.shape)\n","print(y_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"H8qKsb7Gli4s"},"source":["**TSNE()**: \n","\n","**n_components=**: \n","\n","**verbose=**: \n","\n","**random_state=**: \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YnIOk9TLl7n8"},"outputs":[],"source":["tsne = TSNE(n_components=2, verbose=1, random_state=123)\n","z = tsne.fit_transform(x_train)\n","df = pd.DataFrame()\n","df[\"y\"] = y_train\n","df[\"comp-1\"] = z[:,0]\n","df[\"comp-2\"] = z[:,1]"]},{"cell_type":"markdown","metadata":{"id":"qTE7Bzknl9mE"},"source":["**hue**: \n","**df.y.tolist()**: "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Y-peRJOlH9r"},"outputs":[],"source":["sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n","                palette=sns.color_palette(\"hls\", 10),\n","                data=df).set(title=\"MNIST data T-SNE projection\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMFtja18ph0q"},"outputs":[],"source":["# REQUIRE: \n","# aumentar os limites para poder caber a legenda sem sobrepor os pontos.\n","# aumentar o tamanho do gráfico.\n","# adequar com os dados de treino e teste previamente ajustados.\n","# plotar dois gráficos um para treino e outro para teste pós-modelo."]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNq53z20PCzFGfvLW1WGerB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}